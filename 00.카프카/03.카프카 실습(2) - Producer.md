# 카프카 실습(2) - Kafka Producer application

먼저 실습을 위해 다음 레포지토리를 클론해주자.

~~~
% git clone https://github.com/chlalstjd430/tacademy-kafka
~~~

이후 intellij를 통해 simple-kafka-producer 패키지를 열어주자.

<br><br><br>

## Producer

- 카프카로 데이터(key, value) 전송

- ProducerRecord 객체를 생성

- Java Kafka-client 제공

<br>

## SimpleProducer.java

먼저 build.gradle 열어주면 다음과 같은 의존성이 추가되어있는 것을 확인 할 수 있다.

~~~gradle
...

dependencies {
    ...
    compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.5.0'
}
~~~

kafka-clients를 사용하기 위해서는 dependency를 위와 같이 추가되어야한다.

이후 ProduccerWithKeyValue.java 파일을 열어보자. 코드에 대한 설명은 주석에 작성했다.

~~~java
package com.tacademy;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerWithKeyValue {
    private static String TOPIC_NAME = "topictest"; // 토픽 이름(--topic 옵션)
    private static String BOOTSTRAP_SERVERS = "127.0.0.1:9092"; // 부트스트랩 서버 주소(--bootstrap-server 옵션)

    public static void main(String[] args) {
        Properties configs = new Properties();
        // 부트스트랩 서버 설정
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        // key 직렬화 설정
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // value 직렬화 설정
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

        // 0부터 9까지 1초 간격으로 값을 보낸다.
        for (int index = 0; index < 10; index++) {
            String data = "This is record " + index;
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, Integer.toString(index), data);
            try {
                producer.send(record);
                System.out.println("Send to " + TOPIC_NAME + " | data : " + data);
                Thread.sleep(1000);
            } catch (Exception e) {
                System.out.println(e);
            }
        }
    }
}
~~~
위의 코드는 1초마다 
그리고 터미널을 열어 다음과 같은 컨슈머를 실행해주자.


~~~
% ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic topictest -group grouptest01 --from-beginning
~~~

그 다음 ProduccerWithKeyValue.java의 main을 실행하면 아래의 값이 차례대로 읽어지는 것을 알 수 있다.

~~~
This is record 0
This is record 1
This is record 2
This is record 3
This is record 4
This is record 5
This is record 6
This is record 7
This is record 8
This is record 9
~~~

<br><br>

## ProducerWithKeyValue.java

이번에는 "kafka-producer-key-value" 패키지로 이동하여 ProducerWithKeyValue.java를 살펴보자.

~~~java
package com.tacademy;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerWithKeyValue {
    private static String TOPIC_NAME = "topictest"; // 토픽 이름(--topic 옵션)
    private static String BOOTSTRAP_SERVERS = "127.0.0.1:9092"; // 부트스트랩 서버 주소(--bootstrap-server 옵션)

    public static void main(String[] args) {
        Properties configs = new Properties();
        // 부트스트랩 서버 설정
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        // key 직렬화 설정
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // value 직렬화 설정
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

        // 0부터 9까지 1초 간격으로 값을 보낸다
        for (int index = 0; index < 10; index++) {
            String data = "This is record " + index;
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, Integer.toString(index), data);
            try {
                producer.send(record);
                System.out.println("Send to " + TOPIC_NAME + " | data : " + data);
                Thread.sleep(1000);
            } catch (Exception e) {
                System.out.println(e);
            }
        }
    }
}
~~~

위 코드는 다음과 같이 키와 같이 값을 보낸다.

> ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, Integer.toString(index), data);

그리고 이번에는 다음과 같은 명령어로 컨슈머를 실행해주자.

~~~
% ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic topictest --property print.key=true --property key.separator="-"
~~~

그리곡 main을 실행하면 다음과 같은 결과가 나온다.

~~~
% ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic topictest --property print.key=true --property key.separator="-"
0-This is record 0
1-This is record 1
2-This is record 2
3-This is record 3
4-This is record 4
5-This is record 5
6-This is record 6
7-This is record 7
8-This is record 8
9-This is record 9
~~~

만약 키값을 보내지 않았다면 키는 null 값으로 출력된다.

<br>

### Record Key
이러한 record key는 메시지를 구분하는 구분자 역할로 사용된다. 또한 다음과 같은 특징을 갖는다.

- 동일 키, 동일 파티션 적재(default)

    - 순서를 보장하므로, 상태머신으로 사요 가능

    - 역할에 따른 컨슈머 할당 적용 가능

        - key=주문 -> 주문처리하는 컨슈머 애플리케이션

        - key=결제 -> 결제처리하는 컨슈머 애플리케이션
- 레코드 값을 정의하는 구분자

    - 키에 레코드 값 해쉬값을 넣음으로서 중복처리 방지 가능

### Record Value

레코드 값은 실질적으로 전달하고 싶은 데이터이다.

- type 제한 없음

- 데이터 포맷

    - CSV, TSV, JSON, Object 등 서비스의 특징에 맞게 사용 권장

- 포맷을 관리하는 다른 밥ㅇ법

    - 컨플루언트 스키마 레지스트리 : confluentinc/schema-registry

<br><br>

## kafka-producer-exact-partition

이제 kafka-producer-exact-partition 패키지로 이동한다. 그다음 ProducerExactPartition.java 파일을 연다.

~~~java
package com.tacademy;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ProducerExactParition {
    private static String TOPIC_NAME = "test";
    private static String BOOTSTRAP_SERVERS = "{aws ec2 public ip}:9092";
    private static int PARTITION_NUMBER = 1;

    public static void main(String[] args) {
        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

        for (int index = 0; index < 10; index++) {
            String data = "This is record " + index;
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, PARTITION_NUMBER, Integer.toString(index), data);
            try {
                producer.send(record);
                System.out.println("Send to " + TOPIC_NAME + " | data : " + data);
                Thread.sleep(1000);
            } catch (Exception e) {
                System.out.println(e);
            }
        }
    }
}
~~~

이전 코드들과 다른점은 아래와 같다.

~~~java
...

private static int PARTITION_NUMBER = 1;

...

ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, PARTITION_NUMBER, Integer.toString(index), data);


...
~~~

해당 코드는 특정 파티션 번호에만 데이터를 전달하는 것이다. 이렇게 할 경우 특정 파티션은 순서가 보장된다는 특징이 있다.

<br>

### Producer acks

producer에서 kafka로 데이터를 보낼 때 유실이 가능한지 얼마나 빠르게 할건지 정하는 중요한 옵션 중 하나이다.

- acks = 0

    - 가장 속도가 빠름 / 유실 가능성이 높음

    - 프로듀서가 브로커와 소켓연결을 맺어 보낸 즉시 성공으로 간주한다. 즉, 브로커가 정상저긍로 받아서 리더 파티션에 저장했는지 알 수 없다.

    - 팔로워 파티션에도 저장되었는지 알 수 없음

    - 전송 속도가 중요학고 일부 유실되어도 무관한 데이터에 사용

- acks = 1(default)

    - 속도 보통 / 유실 가능성이 있음

    - 프로듀서가 보낸 메시직가 리더 파티션에 정상 저장되었는지 확인

    - 팔로워 파티션에 저장되었는지는 모름

    - 리더 파티션에 저장됙고 해당 브로커가 죽으면 데이터 유실

        - acks=0에 비해 신뢰도는 높지만 아직 유실 가능성은 있음

- acks = all or -1

    - 속도 가장 느림 /  메시지 전달 손실 가능성 없음

    - 프로듀소가 보낸 메시지가 리더, 팔로워 파티션에 정상 저장되었늕 ㅣ호가인

    - 리더 파티션의 데이터가 팔로워 파티션까지 복제될땍가지 기다림

    - 복제가 완료되긱 까지 기다림으로 인해 속도가 느림


## Producer Options

- 필수옵션

    - bootstrap.servers : 카프카 클러스터에 연결하기 위한 브로커 목록

    - key.serializer : 메시지 키 직렬화에 사용되는 클래스

    - value.serializer : 메시지 값을 직렬화 하는데 사용되는 클래스

- 선택옵션

    - acks : 레코드 전송 신뢰도 조절(리플리카)

    - comression.type : snappy, gzip, lz4 중 하나로 압축하여 전송

    - retries : 클러스터 장애엥 대응하여 메시지 전송을 재시도하는 회수

    - buffer.memory : 브로커에 전송될 메시지의 버퍼로 사용 될 메모리 양

    - batch.szie : 여러 데이터를 함께 보내기 위한 레코드 크기

    - linger.ms : 현재의 배치를 전송하기 전까지 기다리는 시간

    - client.id : 어떤 클라이언트인지 구분하는 식별자