# 카프카 실습(2) - Kafka Consumer  application

## Consumer

- 데이터를 가져가는(polling) 주체

- commit을 톹해 읽은 consumer offset을 카프카에 기록'

- Java Kafka-client 제공

- 데이터 저장하는 곳

    - FileSystem, Object Storage, Hadoop, RDBMS, NoSQL 등


- Consumer를 사용하기 위해 Producer와 마찬가지로 아래와 같은 의존성을 추가해주어야한다.

~~~
dependencies {
    ...

    compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.5.0'
}
~~~

<br><br>

## simple-kafka-consumer

먼저 터미널로 Producer를 열어두자.

~~~
./kafka-console-producer.sh --bootstrap-server 127.0.0.1:9092 --topic topictest
~~~

그리고 simple-kafka-consumer 패키지의 SimpleConsumer.java 로 이동하자.

~~~java
package com.tacademy;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class SimpleConsumer {
    private static String TOPIC_NAME = "topictest";
    private static String GROUP_ID = "grouptest01";
    private static String BOOTSTRAP_SERVERS = "127.0.0.1:9092";

    public static void main(String[] args) {
        Properties configs = new Properties();
        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);
        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);

        consumer.subscribe(Arrays.asList(TOPIC_NAME));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(record.value());
            }
        }
    }
}
~~~

참고로 desrializer가 string인데, console producer/consumer의 역/직렬화의 default는 string이다.

이제 mian을 실행하고 아까 터미널에 열어둔 producer에 값을 넣어보자.

~~~
% ./kafka-console-producer.sh --bootstrap-server 127.0.0.1:9092 --topic topictest
>2
>a
>b
>c
>d
>e
>
~~~

그러면 인텔리제이 콘솔창에 아래의 값이 출력되는 것을 확인할 수 있다.

~~~
2
a
b
c
d
e
~~~

<br><br>

## kafka-consumer-auto-commit

이번에는 consumer에서 commit이 어떻게 사용되는지 확인하도록 하자. 이를 위해 kafka-consumer-auto-commit 패키지의 ConsumerWithAutoComit.java 로 이동하자

~~~java
package com.tacademy;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class ConsumerWithAutoCommit {
    private static String TOPIC_NAME = "topictest";
    private static String GROUP_ID = "grouptest01";
    private static String BOOTSTRAP_SERVERS = "127.0.0.1:9092";

    public static void main(String[] args) {
        Properties configs = new Properties();
        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);
        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
        configs.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 60000);

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
        consumer.subscribe(Arrays.asList(TOPIC_NAME));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(record.value());
            }
        }
    }
}
~~~

해당 클래스를 실행해보고, 터미널의 producer에 값을 차례대로 넣어보자.

~~~
 ./kafka-console-producer.sh --bootstrap-server 127.0.0.1:9092 --topic topictest
> 1
>2
>3
>4
>5
~~~

그럼 intellij console창에 아래의 값이 출력될 것이다.

~~~
1
2
3
4
5
~~~

그리고 main을 종료하고 다시 켜보자. 그러면 아래의 값이 다시 출력되는 것을 확인 할 수 있다.

~~~
4
5
1
2
3
~~~

이는 우리가 1분마다 commit을 하도록 설정했는데, 1분이 지나지않은 채 consumer를 닫아 commit이 되지않아 다시 데이터를 불러오는 것이다.

### Consumer commit

- enable.auto.commit = true (default)

    - 일정 간격(auto.commit.interval.ms), poll() 메서드 호출시 자동 commit

    - commit 고간련 코드를 작성할 필요가 없어 편리하다.

    - 속도가 가장 빠르다.

    - 중복 또는 유실이 발생할 수 있음

        - 중복/유실을 허용하지 않는 곳(은행,카드)에서는 사용하면 안됨 .  

- enable.auto.commit = false

    ~~~java
    configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
    ~~~

    - commitSyncc() : 동기 커밋

        - commitSync()

            ~~~java
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.println(record.value());
                }
                try {
                    consumer.commitSync();
                } catch(CommitFailedException e) {
                    System.err.println("commit failed");
                }
            }
            ~~~

        - Map<TopicPartition, OffsetAndMetadata>을 통해 오프셋 지정 커밋 가능

            ~~~java
            Map<TopicPartition, OffsetAndMetadata> offset = new HashMap<>();
            offset.put(new TopicPartition(record.topic(), record.partition()), null);
            try {
                consumer.commitSync(offset);
            } catch(CommitFailedException e) {
                System.err.println("commit failed");
            }
            ~~~

        - ConsumerRecord 처리 순서를 보장함

        - 가장 느림(커밋이 완료될 떄 까지 block)

        - poll() 메서드로 반환된 ConsumerRecord의 마지막 offset을 커밋

        

    - commitAsync() : 비동기 커밋

        - commitAsync()

            ~~~
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.println(record.value());
                }
                consumer.commitAsync();
            }   
            ~~~

        - 동기 커밋보다 빠름

        - 중복이 발생할 수 있음

        - ConsumerRecord 처리 순서를 보장하지 못함

    - commitAsync() + commitSync() : 비동기, 동기 커밋 같이 쓰기

        ~~~~
        try {
            while(true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofSecond(1));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.println(record.value());
                }
                consumer.commitAsync();
            }
        } catch(CommitFailedException e) {
            System.err.println("commit failed");
        } finally {
            consumer.commitSync();
        }
        ~~~

<br><br>

## Consumer rebalance

컨슈머 그룹의 파티션 소유권이 변경될 때 일어나는 현상

- 리밸런스를 하는 동안 일시적으로 메시지를 가져올 수 없음

- 리밸런스 발생시 데이터 유실/주우복 발생 가능성 있음

    - commitSync() 또는 추가적인 방법(unique key)으로 데이터 유실/중복 방지

- 언제 리밸런스 발생?

    - consumer.close() 호출시 또는 consumer의 세션이 끊어졌을 때

<br><br>

## Consumer rebalance listener

~~~java
    ...

    consumer.subscribe(Arrays.asList("test"), new RebalanceListener());
    while (true) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
        for (ConsumerRecord<String, String> record : records) {
            System.out.println(record.value());
        }
    }
    static class RRebalanceListenerr implements ConsumerRebalanceListener {
        // 파티션이 끊어졌을 때
        @Override
        public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
            System.put.println("Lost partitions");
        }

        // 파티션이 할당 되었을 때
        @Override
        public void onParttitionsAssigned(Collection<TopicPartition> partitions) {
            System.out.println("Assigned partitions");
        }
    }
~~~

- 리밸런스 발생에 따른 offset commit

- 립밸런스 시간 측정을 통한 컨슈머 모니터링

<br><br>

## Consumer wakeup

consumer를 정상적으로 종료시키기 위해 사용하는 method




**SIGKILL(강제 애플리케이션 종료)로 인한 중복 처리 발생 예시**

~~~java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record.value());
    }
    consumerr.commitSync();
}
~~~

1. poll() 호출

    - 마지막 커밋된 오프셋이 100

    - records 100개 반환 : 오프셋 101 ~ 200

2. records loop 구문 수행

3. record.value() 150번 오프셋 출력중, SIGKILL 호출

    - 101 ~ 150 오프셋 처리 완료 / 151 ~ 200 오프셋 미처리

4. 다시 poll() 호출

    - 브로커에 100번 오프셋이 마지막 커밋

        - 컨슈머 재시작시 다시 오프셋 101부터 처리 시작

        - 즉, 101 ~ 150번 중복 처리 발생


위와 같은 상황을 예방하긱 위해 아래와 같이 shutdownhook을 설정해준다.

~~~java
Runtime.getRuntime().addShutdownHook(new Thread() {
    public void run() {
        consumer.wakeup();
    }
});
~~~

그러면 아래의 코드에서 SIGKILL 발생시 WakeupException을 받을 수 있다..

~~~java
try {
    while (true) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
        for (ConsumerRecord<String, String> record : records) {
            System.out.println(record.value());
        }
        consumerr.commitSync();
    }
} catch (WakeupException e) {
    System.out.println("poll() method trrigger WakeupException");
} finally {
    consumer.commitSync();
    cocnsumer.close();
}

~~~

<br><br>

## kafka-consumer-multi-thread

이번에는 Consumer thread 전략에 대해 알아보자.

### 1안) 1 프로세스 + 1 스레드(컨슈머)

- 간략한 코드

- 프로세스 단위 실행/종료

- 다수의 컨슈머 실행 필요시 다수의 프로세스 실행 필요

- 애플리케이션을 jar파일이라하고 실행시키면

    ~~~
    % cat consumer.conf
    {"topic":"click_log", "group_id":"hadoop-consumerrs"}

    % java -jar one-process-one-consumer.jar --path consumer.conf
    ~~~

<br>

### 2안) 1프로세스 + n스레드(동일 컨슈머 그룹)

- 복잡한 코드

- 스레드 단위 실행/종료

- 스레드간 간섭 주의(세마포어, 데드락 등)

- 다수 컨슈머 실행시 다수 스레드 실행 가능

~~~
% cat consumer.conf
{"topic":"click_log", "group_id":"hadoop-consumerrs", "consumer.no":20}

% java -jar one-process-one-consumer.jar --path consumer.conf
~~~

<br>

### 3안) 1프로세스 + n스레드(다수 컨슈머 그룹)

- 복잡한 코드

- 컨슈머 그룹별 스레드 개수 조절 주의

~~~
% cat consumer.conf
[
    {"topic":"click_log", "group_id":"hadoop-consumerrs", "consumer.no":20},
    {"topic":"click_log", "group_id":"elasticsearch-consumers", "consumer.no":1},
    {"topic":"application_log", "group_id":"hadoop-consumerrs", "consumer.no":5}
]

% java -jar one-process-one-consumer.jar --path consumer.conf
~~~

### ConsumerWithMultiThread.java / ConsumerWorker.java

그럼이제 실습을 한번 해보자. 실습하는 방안은 "한개의 프로세스에 여러개의 스레드를 실행" 이다. 먼저 simple-kafka-consumer 패키지로 이동하자.

ConsumerWorker.java

~~~java
package com.tacademy;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.errors.WakeupException;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class ConsumerWorker implements Runnable {
    private Properties prop;
    private String topic;
    private String threadName;
    private KafkaConsumer<String, String> consumer;

    // 생성시 설정/토픽 정보 가져옴
    ConsumerWorker(Properties prop, String topic, int number) {
        this.prop = prop;
        this.topic = topic;
        this.threadName = "consumer-thread-" + number;
    }

    // 스레드 실행시
    @Override
    public void run() {
        consumer = new KafkaConsumer<>(prop);
        consumer.subscribe(Arrays.asList(topic));
        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.println(threadName + " >> " + record.value());
                }
                consumer.commitSync();
            }
        } catch (WakeupException e) {
            System.out.println(threadName + " trigger WakeupException");
        } finally {
            consumer.commitSync();
            consumer.close();
        }
    }

    // poll 수행시 wakeupexception 발생을 위한 method
    public void shutdown() {
        consumer.wakeup();
    }
}
~~~

~~~java
package com.tacademy;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.util.ArrayList;
import java.util.List;
import java.util.Properties;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class ConsumerWithMultiThread {
    private static String TOPIC_NAME = "topictest";
    private static String GROUP_ID = "grouptest01";
    private static String BOOTSTRAP_SERVERS = "127.0.0.1:9092";
    private static int CONSUMER_COUNT = 3; // 컨슈머 개
    private static List<ConsumerWorker> workerThreads = new ArrayList<>();

    public static void main(String[] args) {
        Runtime.getRuntime().addShutdownHook(new ShutdownThread()); //shutdown시 wakeup을 위한 설
        Properties configs = new Properties();
        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);
        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

        ExecutorService executorService = Executors.newCachedThreadPool(); // thread가 완료되면 스레드가 죽는다.
        for (int i = 0; i < CONSUMER_COUNT; i++) {
            ConsumerWorker worker = new ConsumerWorker(configs, TOPIC_NAME, i);
            workerThreads.add(worker); // 강제 종료시 일괄적인 wakeup 처리를인 위해 리스트에 저장
            executorService.execute(worker);
        }
    }

    static class ShutdownThread extends Thread {
        public void run() {
            workerThreads.forEach(ConsumerWorker::shutdown);
            System.out.println("Bye");
        }
    }
}
~~~

이후 터미널로 producer를 열고 main을 실행해보자.

~~~
% ./kafka-console-producer.sh --bootstrap-server 127.0.0.1:9092 --topic topictest
>f
>e
>a
>1
>2
>3
>4
>5
>6
>7
>8
>9
>0
>
~~~

그럼 아래 콘솔을 통해 각 컨슈머다 데이터를 각각 polling하여 처리하는 것을 확인할 수 있다.
~~~
consumer-thread-1 >> f
consumer-thread-1 >> e
consumer-thread-1 >> a
consumer-thread-0 >> 1
consumer-thread-0 >> 2
consumer-thread-0 >> 3
consumer-thread-2 >> 4
consumer-thread-2 >> 5
consumer-thread-2 >> 6
consumer-thread-1 >> 7
consumer-thread-1 >> 8
consumer-thread-1 >> 9
consumer-thread-0 >> 0
~~~

이제 해당 컨슈머들을 안전하게 종료하자. 이후 새롭게 터미널 창을 열고 "jps"를 입려하여 pid 번호를 찾아 kill 해주자.

~~~
% jps             
1059 GradleDaemon
2102 ConsumerWithMultiThread
1786 ConsoleProducer
2203 Jps
765 

% kill -term 2102 
~~~

<br><br>

## Consumer lag 

consumer lag은 "컨슈머 마지막 커밋 오프셋 ~ 토픽의 마지막 오프셋" 이다. 

- 컨슈머 랙은 컨슈머의 상태를 나타내느 지표

- 컨슈머 랙의 최대값은 컨슈머 인스턴스를 통해 직ㅈ버 확인할 수 있음

    - consumer.metrics()를 통해 확인할 수 있는 지표

        ~~~java
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            Map<MetricName, ? extends Metric> metrics = consumer.metrics();
            for (MetricName metric : metrics.keySet()) {
                System.out.println(metric.name() + "is " + metrics.get(metric).metricValue());
            }
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(record.value());
            }
        }
        ~~~

        - records-lag-max : 토픽의 파티션 중 최대 랙

        - fetch-size-avg : 1번 polling하여 가져올 때 레코드 byte 평균

        - fetch-rate : 1초 동안 레코드 가져오는 회수

- 컨슈머 인스턴스를 통한 컨슈머 랙 수집의 문제점

    - 컨슈머 인스턴스 장애가 발생하면 지표 수집 불가능

    - 구현하는 컨슈머마다 지표를 수집하는 로직 개발 필요

    - 컨슈머 랙 최대값(records-lag-max)만 알 수 있음

        - 토픽에 파티션은 n개가 있을 수 있음.

        - 최대값을 제외한 나머지 파티션의 컨슈머 랙은 알 수 없음.

- 컨슈머 랙 모니터링

    - 외부 모니터링 애플리케이션 사용하면 컨슈머 인스턴스를 사용했을 때 생기는 문제점 해결 가능

    - Confluent Platform, Datadog, Kafka Burrow(Open Source)

    - Kafka Burrow

        - [설치 방법](https://blog.voidmainvoid.net/279)

        - Linkedin에서 오픈소스로 제공하는 컨슈머 랙 체크 툴

        - 버로우 실행 시 Kafka, Zookeeper 정보를 통해 랙 정보 자체 수집

        - 슬라이딩 윈도우를 통한 컨슈머 상태 정의

            - OK : 정상

            - ERROR : 컨슈머가 polling을 멈춤

            - WARNING : 컨슈머가 polling을 수행하지만 lag이 계속 증가